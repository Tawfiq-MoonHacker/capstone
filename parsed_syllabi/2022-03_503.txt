Course Syllabus - SIADS 503: Data Science Ethics Part I. Course Basics Course Overview and Prerequisites This class will teach you to recognize where ethical issues can arise when applying data science to real world problems. It will bring more analytic precision to ethical debates about the role that data science, machine learning, and artificial intelligence play in consequential decision-making in commerce, employment, finance, healthcare, education, policing, and other areas. Largely through discussion of case studies, we will focus on ways to conceptualize, measure, and mitigate harm in data-driven decision-making. You will learn to think critically about how to plan and evaluate a data science project with ethical concerns in mind, and how to cope with novel challenges for which there are often no easy answers or established solutions. To do so, you will learn key technical, ethical, policy, and legal terms and concepts that are relevant to ethical assessment in data science; learn about some of the common approaches and emerging tools for mitigating or managing these ethical concerns; and gain exposure to readings that will help you understand the current ethical and regulatory environment and to anticipate future developments. Ultimately, the class will teach you how to reason through these problems in a systematic manner and how to justify and defend your approach to dealing with them. The prerequisites for this course are admission into the Masters in Applied Data Science program and successful completion of SIADS 501, “Being a Data Scientist.” Instructional Team For this course, we have a primary instructor, two supporting instructors (who also teach other courses in MADS and elsewhere at UMSI), and five GSIs. Primary Instructor: Dr. Melissa Chalmers Lecturers/Secondary Instructors: Merve Hickok, Dr. Nick Sheltrown Graduate Student Instructors: Ruth Corddry, Sylvia Darling, Liz Giancola, Eric Kim, Ali Tobah Communications Expectations Slack is the primary communication mechanism between the instructional team and students for this course. If you do not use Slack, you will likely miss out on important updates, feedback, and discussions on topics of interest to the course. Course channel in Slack = siads503_wi22_001 Slack response time: within 24 hours. Email response time: N/A; please use Slack Office Hours: Saturdays 11 am - 12 pm; Mondays 7-8 pm. Both are Eastern Time and held on Zoom. Please refer to the Live Events section in Coursera for links. How to Get Help This is a large class, but it’s still easy to get help if you need it: Questions likely to be of general interest to other students in the class: please post to the course Slack channel. Note that there will be pinned posts for conversations about each of the four weekly assignments. To request additional individualized feedback or support on weekly assignments: If you got feedback that you are having trouble understanding, or perhaps you disagree with it and would like some substantive advice on how to improve in future weeks, please follow these steps: Write up as specific a question as you can, including enough context for the instructor team to understand it. Be sure to include your best interpretation of what the feedback is telling you. Send a slack DM to the 503 lecturers (@Melissa Chalmers, @Merve Hickok, @Nick Sheltrown) with your question or concern (written up as an attachment or inline within slack). One of us will get back to you in the slack thread, usually within 24 hours. If you have questions concerning the degree program or encounter issues using Slack , please email umsimadshelp@umich.edu . If you have an issue specific to the Coursera environment, you can begin a live chat session with Coursera Technical Support (24/7) or view Coursera troubleshooting guides . (you may be asked to log in to your Coursera account). Required Textbook You will be given a list of required and recommended readings within the course. Online access to these readings are provided through the University of Michigan Library or through approved online sources. For resources provided through the library, you will be asked to sign in with your UMich uniqname and password to access these materials. There is no required textbook for this course that needs to be purchased separately from a bookstore. Learning Outcomes Achieve literacy on the potential harms of data collection, aggregation, and analysis typically found in applied data science contexts. Achieve literacy in the most important terminology of ethics that applies to data science. Achieve literacy in writing ethical assessments (e.g., a memorandum) of a data science analysis or an automated system incorporating data science. Achieve competency in articulating the reasoning behind the most important ethical challenges of data science as applied to course domains of privacy, bias/classification, provenance/aggregation and accountability/consequences. Please note that you will also see "Learning Objectives" listed at the start of each week. Think of these as "Goals for This Week." Course Structure Each week, this course consists of recorded lectures, required and recommended readings ,  and two office hours produced by the teaching team. Lectures consist of overview material about concepts as well as the discussion of case studies. In addition, a guest speaker will visit or we will take a field trip. This will provide one or more additional recorded lectures, interviews, or conversations. Lectures supplement but do not always review or duplicate the readings; readings supplement but do not always duplicate the lectures. That means some of the course content is available only from a lecture or a reading. For instance a concept may not be mentioned in a lecture, but it may be the key point of a reading. Students are still responsible for that material. A low-stakes, open-book weekly quiz will provide an incentive to keep up with the readings/lecture content. The primary work of the course is one writing assignment each week. Office hours offer us the opportunity for the teaching team and students to discuss course topics more informally; there will be opportunities for both student-generated questions and conversation as well as teaching-team led presentations of content related to both course topics and assignments. We also hope to welcome some guests to shed light on how ethics issues manifest in real-life professional situations. Course Deadlines This course begins on Wednesday, March 2 and ends on Tuesday, March 29, 2022 . Weekly Quizzes and Writing Assignments will be due on Tuesdays at 11:59 pm (time zone is Ann Arbor, Michigan; Eastern Time). The Extra Credit assignment will be due on Tuesday, March 29  at 11:59 pm (time zone is Ann Arbor, Michigan; Eastern Time). Grading Assignment type - % of Final Grade Weekly Quizzes (4 quizzes; lowest score dropped) - 10% Weekly Writing Assignments - 90% Week 1: Memo about a privacy concern (15%) Week 2: Evaluation of the What-If Tool (25%) Week 3: Perform an algorithmic impact assessment (25%) Week 4: Design an ethics oath, pledge, or checklist (25%) Extra Credit – Write Your Own Quiz Questions - (up to 2.5% EC) Note: You are required to attempt/complete all assignments (except extra credit) in order to earn credit for this course. Letter Grades, Course Grades, and Late Submission Policy Refer to the MADS Assignment Submission and Grading Policies section of the UMSI Student Handbook (access to Student Orientation course required) Final letter grades for the course will be calculated using the following scale: A+ 98%; A 93-97%; A- 90-92%; B+ 87-89%; B 83-86%; B- 80-82%; C+ 77-79%; C 73-76%; C- 70-72%; D+ 67-69%; D 63-66%; D- 60-62%; E 59% or below. Coursera does not round up or down (e.g. 86.78% = B). Late submissions receive 10% penalty per day. If you think you need an extension for an assignment, please DM the course instructor @Melissa Chalmers in advance of the assignment deadline. Regrade Requests Policy Graders may make mistakes. Gradescope has a system for regrade requests; please use it to request review of an assignment, and describe why you think that the initial grading was incorrect. Regrade requests will be handled by a different grader. The entire assignment will be regraded, applying all elements of the grading rubric. Your grade could go up or down. Revise and Resubmit You will have the opportunity to revise and resubmit one assignment. This is not required, but is rather an opportunity to earn additional points by responding to feedback and improving your submission. II. Additional Course Policies Academic Integrity Collaboration UMSI strongly encourages collaboration while working on some assignments, such as work on team projects and interpreting reading assignments as a general practice. Active learning is effective. You must, however, write your individual assignment submissions on your own, in your own words. You should not collaborate on quizzes. Read the instructions carefully and request clarification about collaboration when in doubt. Plagiarism Unless otherwise specified in an assignment, all submitted work must be your own original work. Any excerpts, statements, or phrases from the work of others must be clearly identified as a quotation, and a proper citation provided. In this course, an assignment containing plagiarized material will receive zero points. This applies whether the plagiarism is intentional or inadvertent. Any violation of the School’s policy on Academic and Professional Integrity (stated in the MADS Student Handbook ) will also be reported to UMSI Student Affairs. The University Library also offers information about academic integrity and how you can protect yourself. If you are unsure about whether a passage in your writing constitutes plagiarism, you are encouraged to seek help from the teaching team or from the Sweetland Writing Center. Be sure to plan sufficiently ahead in your writing so that you can receive and incorporate feedback if you are uncertain about the boundaries of plagiarism. Accommodations Refer to the Accommodations for Students with Disabilities section of the UMSI Student Handbook (access to the Student Orientation course required). Use the Student Intake Form to begin the process of working with the University’s Office of Services for Students with Disabilities. Library Access Refer to the U-M Library’s information sheet on accessing library resources from off-campus. For more information regarding library support services, please refer to the U-M Library Resources section of the UMSI Student Handbook (access to the Student Orientation course required). Student Mental Health Refer to the University’s Resources for Stress and Mental Health website for a listing of resources for students. Student Services Refer to the Introduction to UMSI Student Life section of the UMSI Student Handbook (access to the Student Orientation course required). III. Course Schedule Week 1: Introduction and Data Privacy Framing Questions: What is Data Science Ethics? Does Data Science Hate Privacy? Is Privacy-Respecting Data Science Even Possible? Major Class Topics This Week: The 15 Top Misconceptions About Data Science Ethics What is a “patient” or “stakeholder”? Special Guest: Amanda Stanhaus, School of Public Health, University of Michigan and Fellow, US National Institutes of Health Additional Key Concepts: Ethics vs. law/compliance/public relations; cultural relativism; “professional” ethics in data science; individuals vs. collectives; the “nothing to hide” argument; the “Fair Information Practice Principles” and their problems; The Belmont Report principles; informed consent; privacy dependencies Required Readings: Loukides, Mike, Hilary Mason, and DJ Patil. 2018. Ethics and Data Science. Sebastopol, CA: O’Reilly Media. Chapter 1, “Doing Good Data Science” Loukides, Mike, Hilary Mason, and DJ Patil. 2018. Ethics and Data Science. Sebastopol, CA: O’Reilly Media. Chapter 3, “The Five Cs.” Zook, Matthew, Solon Barocas, Kate Crawford, Emily Keller, Alyssa Goodman, Rachelle Hollander, Barbara A. Koenig, Jacob Metcalf, Arvind Narayanan, Alondra Nelson, and Frank Pasquale. 2017. “Ten Simple Rules for Responsible Big Data Research.” PLOS Computational Biology 13(3):1–11. Solove, Daniel J. 2007. "'I’ve Got Nothing to Hide’ and Other Misunderstandings of Privacy.” San Diego Law Review 44(May):1–23. Read the following sections: II. p 748- 753; IV. 764-772. VIDEO: The New York Times - Blood Journey by Kassie Bracken & Amy Harmon . April 2010. (11 minutes) Solove, Daniel J. 2013. “Introduction: Privacy Self-Management and the Consent Dilemma.” Harvard Law Review 126(7):1880–1903. Read the following section ONLY: I. pp. 1882 – 1893. Assessments Due: Week #1 Quiz Whistleblower Memo About a Privacy Concern Week 2: Bias and Classification Framing Questions: Is Data Science Backward-Looking? Is it Inherently Discriminatory? Major Class Topics This Week: Classification Cumulative Disadvantage and Protected Classes What is a “harm”? Field Trip: Project Green Light : University of Michigan Detroit Center; Detroit’s Corktown Green Light District Special Guest: Tawanna Petty ,Director of Data Justice Programming for the Detroit Community Technology Project. Additional Key Concepts: harm without intent; objectivity/neutrality; bias toward the majority; error analysis; team diversity Required Readings: American Civil Liberties Union. (2004). "Scary Pizza." (video.) 01:42. Available online: https://www.youtube.com/watch?v=33CIVjvYyEk Raji, Deborah. (December 10, 2020). " How our data encodes systematic racism ." MIT Technology Review. Wallach, Hanna. (December 14, 2014). Big Data, Machine Learning, and the Social Sciences: Fairness, Accountability, and Transparency. Medium.com. Angwin, Julia; Larson, Jeff; Mattu, Surya, Kirchner, Lauren. (June 6, 2016). Machine Bias: Two Drug Possession Arrests. The Louisiana Weekly; New Orleans, LA. pp. 1,6. Harmon, Amy. (July 8, 2019) . As Cameras Track Detroit's Residents, a Debate Ensues Over Racial Bias . New York Times. Citron, Danielle Keats, and Frank A. Pasquale. (2014). "The Scored Society: Due Process for Automated Predictions." Washington Law Review 89. Practice materials for this week’s assignment: The What-If tool. Specifically, the COMPAS Recidivism Classifier “Notebook Demo With Attributions” dataset for the What-If Tool: https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_COMPAS_with_SHAP.ipynb See also the What-If Tool documentation, e.g., the walkthrough https://pair-code.github.io/what-if-tool/walkthrough.html (optional), or introductory videos about the tool on YouTube https://www.youtube.com/results?search_query=%23whatiftool (optional). Assessments Due: Week #2 Quiz Memo Evaluating the What-If Tool Week 3: Accountability and Governance Framing Questions: Can large, automated systems be effectively controlled? When are YOU responsible? Major Class Topics This Week: How Transparency Works and Doesn’t Work Algorithm Auditing, External Auditing, and Reverse Engineering How should we consider “power” and regressing/progressive acts in data science ethics? Special Guest : J. M. Porup , a freelance cybersecurity reporter whose work has appeared in The Economist , Vice , Ars Technica , Motherboard , and elsewhere. Special Guest : Sol Bermann , Former Director of International Privacy, Walmart Corporation; current Chief Information Security Officer, University of Michigan. Additional Key Concepts: governance; accountability workflows; consequences predictable by experts vs. discoverable by users; approaches to auditing; algorithmic accountability reporting; reverse engineering. Required Readings: Ananny, Mike and Kate Crawford. (2018) "Seeing without knowing: Limitations of the transparency ideal and its application to algorithmic accountability." New Media & Society 20.3: 973-989. Sandvig, Christian, Kevin Hamilton, Karrie Karahalios, and Cedric Langbort. (2014). "Auditing Algorithms: Research Methods for Detecting Discrimination on Internet Platforms." Computational Culture. Kalluri, Pratyusha. (2020, July 7) Don’t ask if artificial intelligence is good or fair, ask how it shifts power . Nature . Diakopoulos, Nicholas. (2015). ‘ ‘Algorithmic Accountability.’’ Digital Journalism 3 (3): 398-415. Grothoff, Christian & J.M. Porup. (2016, February 16). The NSA's SKYNET program may be killing thousands of innocent people. Ars Technica. Harwell, Drew. (2019). Colleges are turning students' phones into surveillance machines, tracking the locations of hundreds of thousands. The Washington Post. Assessments Due: Week #3 Quiz Memo Evaluating the What-If Tool Week 4: Data Provenance and Aggregation; Course Conclusion Framing Questions: Does data science always leave something out? Are data ever truly portable? Major Class Topics This Week: Challenges of “public” data Sampling as an ethical problem What is a “norm”? What are grounds by which we make ethical claims? Special Guest : Kathy Pham , founder, Ethical Tech Collective; former founding member, Product and Engineering Team, United States Digital Service, The White House. Additional Key Concepts: provenance (a.k.a. origination); sampling bias; aggregation; retention; disposition; forgetting / erasure; building ethics into a data science culture Required Readings: Rieder and Simon (2016) Datatrust: Or, the political quest for numerical evidence and the epistemologies of Big Data. Big Data & Society 3(1): 1–6. Loukides, Mike, Hilary Mason, and DJ Patil. 2018. Ethics and Data Science. Sebastopol, CA: O’Reilly Media. Chapter 2, “Of Oaths and Checklists” Loukides, Mike, Hilary Mason, and DJ Patil. 2018. Ethics and Data Science. Sebastopol, CA: O’Reilly Media. Chapter 4, "Data's Day of Reckoning" Assessments Due: Week #4 Quiz Design and Ethics Oath, Pledge, or Checklist IV: Bibliography of Additional Readings These are additional recommended readings that may be of interest. (Listed by week and topic.) Overall D'Ignazio, C. and Klein, L.F., 2020. Data feminism . MIT Press. O'Neil, Cathy. 2014. On being a data skeptic . O'Reilly Media, Inc. Salganik, Matthew J. 2019. Bit by bit: Social research in the digital age . Princeton University Press. Chapter 6 - Ethics. https://www.bitbybitbook.com/en/1st-ed/ethics/ Metcalf, Jacob, Emanuel Moss, and danah boyd. 2019. “Owning Ethics: Corporate Logics, Silicon Valley, and the Institutionalization of Ethics.” Social Research: An International Quarterly 82(2):449–76. Cornell Tech - Good Code Podcast. Episode 8: Solon Barocas on Teaching Ethics in Data Science. Ananny, Mike. 2016. “Toward an Ethics of Algorithms : Convening Observation , Probability , and Timeliness.” Science, Technology, & Human Values 41(1):93–117. Natasha Singer. Tech's Ethical 'Dark Side': Harvard, Stanford and Others Want to Address It. The New York Times. February 12, 2018. Moor, James. H. 2005. “Why We Need Better Ethics for Emerging Technologies,” Ethics and Information Technology 7:111-119. [8 pages] Brey, Philip A. E. 2012. “Anticipating Ethical Issues in Emerging IT.” Ethics and Information Technology 2012 [13 Pages]. Privacy Cate, Fred H. 2006. “The Failure of Fair Information Practice Principles.” From Consumer Protection in the Age of the “Information Economy” by Jane K. Winn and Professor Geraint Howells. Read ONLY the following sections: pp. 345-348; pp. 352-353; pp. 356-365; pp. 369-374. Federal Trade Commission - Consumer Information. Direct-to-Consumer Genetic Tests. Messner, Donna A. (2011). Informed choice in direct-to-consumer genetic testing for Alzheimer and other diseases: lessons from two cases. New Genetics and Society, 30, 59-72. Udesky, Laurie. 2011. “The Ethics of Direct-to-Consumer Genetic Testing.” The Lancet 376(9750):1377–78. Cornell Tech - Good Code Podcast. Episode 2: Helen Nissenbaum on Post-Consent Privacy. March 26, 2019. Allyse MA et al. (2018). Direct-to-consumer genetic testing 2.0: Emerging models of direct-to-consumer genetic testing. Mayo Clinic Proceedings, 93(1), 113-20 Kowal, Emma, Joanna Radin, and Jenny Reardon. 2013. “Indigenous Body Parts, Mutating Temporalities, and the Half-Lives of Postcolonial Technoscience.” Social Studies of Science 43:465. Mcguire, Amy L. and Laura M. Beskow. 2010. “Informed Consent in Genomics and Genetic Research.” Annual Review of Genomics and Human Genetics 11(361–81). Cate, F.H. and Mayer-Schonberger, V. Notice and consent in a world of big data. International Data Privacy Law 3, 2 (May 20, 2013), 67–73. Narayanan, Arvind and Shmatikov, Vitaly. (2010). Privacy and Security: Myth and Fallacies of "Personally Identifiable Information." Communications of the ACM 53 (6): 26. Barocas, S., & Nissenbaum, H. (2014). Computing Ethics: Big data's End Run Around Procedural Privacy Protections. Communications of the ACM 57 (11): 31-33. Schermer, B. W., Custers, B. H. M., & Van der Hof, S. (2014). The crisis of consent: How stronger legal protection may lead to weaker consent in data protection. Helm, Paula. 2018. “Treating Sensitive Topics Online: A Privacy Dilemma.” Ethics and Information Technology 20:303–13. Sambasivan, N., Checkley, G., Batool, A., Ahmed, N., Nemer, D., Gaytán-Lugo, L. S., ... & Churchill, E. (2018). " Privacy is not for me, it's for those rich women": Performative Privacy Practices on Mobile Phones by Women in South Asia. In Fourteenth Symposium on Usable Privacy and Security ({SOUPS} 2018) (pp. 127-142) . https://nithyasambasivancom.files.wordpress.com/2018/06/performativeprivacy_soups.pdf Bias and Classification Noble, S.U., 2018. Algorithms of oppression: How search engines reinforce racism . NYU Press. Benjamin, R., 2019. Race After Technology: Abolitionist Tools for the New Jim Code . Polity Press. Eubanks, V., 2018. Automating inequality: How high-tech tools profile, police, and punish the poor . St. Martin's Press. boyd, danah, Karen Levy, and Alice Marwick. (2014). "The Networked Nature of Algorithmic Discrimination." Open Technology Institute. Bowker, Geoffrey C. and Star, Susan Leigh. “Some Tricks of the Trade in Analyzing Classification,” in Sorting Things Out: Classification and Its Consequences, pp. 33-50, Cambridge, MA: MIT Press, 1999 Sandvig, Christian. (2015). "Seeing the Sort: The Aesthetic and Industrial Defense of 'The Algorithm." Media-N: Journal of the New Media Caucus 10(3). Joy Buolamwini & Timnit Gebru. (2017). Gender Shades: Intersectional Accuracy Disparities in Commercial Gender Classification. Proceedings of Machine Learning Research 81: 77-91. Chen, L., Ma, R., Hannak, A., & Wilson, C. (2018). Investigating the Impact of Gender on Rank in Resume Search Engines. Proceedings of the 2018 ACM Conference on Computer-Human Interaction (CHI'18). Haimson, Oliver L. and Anna Lauren Hoffmann. 2016. “Constructing and enforcing ‘authentic’ identity online: Facebook, real names, and non-normative identities.” First Monday 21 (June). [15 pages]. Angwin, Julia; Larson, Jeff; Kirchner, Lauren; and Mattu, Surya. (2017, 5 April) Minority neighborhoods pay higher car insurance than white neighborhoods with the same risk. ProPublica, co-published with Consumer Reports. Accountability and Governance Karppi, Tero, and Kate Crawford. 2015. “Social Media, Financial Algorithms and the Hack Crash.” Theory, Culture & Society 33 (1): 73–92. boyd, danah. (2017) Toward Accountability: Data, Fairness, Algorithms, Consequences. Data and Society: Points. [blog post] Pasquale, Frank. (2015). The Black Box Society: The Secret Algorithms That Control Money and Information. Cambridge: Harvard University Press. Especially the following chapters: Ch. 1: “The Need to Know” and Ch. 6: “Toward an Intelligible Society.” Pasquale, Frank. (2006). Rankings, Reductionism, and Responsibility. Cleveland State Law Review, 54: 115+ Professional Pledges, Oaths, and Checklists Simonite, Tom. 2018, February 8. "Should Data Scientists Adhere to a Hippocratic Oath?" Wired : Business. https://www.wired.com/story/should-data-scientists-adhere-to-a-hippocratic-oath/ United Nations. 1948. Universal Declaration of Human Rights . https://www.un.org/en/universal-declaration-human-rights/ V. Acknowledgements 2021: This course has evolved (and continues to evolve) in scope, structure, and content thanks to the perspectives, feedback, and continuous investment of attention by the instructional staff and MADS students. 2019: Thank you to Casey Fiesler, Natalie Garrett, and Nathan Beard’s work on ethics and their ethics syllabi research project. This syllabus is in debt to the syllabi of Paul Conway. Thanks for specific suggestions from Solon Barocas and Karrie Karahalios. Thank you to our generous beta-testers and guest speakers, as well as to James Wexler, Fernanda Viegas, and Google PAIR (People + AI Research). Finally, general thanks to the Ethical Tech Collective and the FAT* community.